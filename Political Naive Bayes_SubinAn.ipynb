{"cells":[{"cell_type":"markdown","metadata":{"id":"a62M7I8Ad_cS"},"source":["# Naive Bayes on Political Text\n","\n","In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J4d-2MGqeGI3","executionInfo":{"status":"ok","timestamp":1727843058172,"user_tz":300,"elapsed":22308,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"6c95e222-d1f1-4a60-d1fe-e5d568c6e564"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GdvInJFOd_cW","executionInfo":{"status":"ok","timestamp":1727843924710,"user_tz":300,"elapsed":241,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"40193797-e1a4-4092-a620-f8876491d569"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import sqlite3\n","import random\n","import numpy as np\n","from collections import Counter, defaultdict\n","import re\n","import string\n","import nltk\n","\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.tokenize import sent_tokenize\n","\n","# Feel free to include your text patterns functions\n","#from text_functions_solutions import clean_tokenize, get_patterns"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"OAJ_8t7Id_cY","executionInfo":{"status":"ok","timestamp":1727843131293,"user_tz":300,"elapsed":1063,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["convention_db = sqlite3.connect(\"/content/drive/MyDrive/ADS-509-01/Module4/2020_Conventions.db\")\n","convention_cur = convention_db.cursor()"]},{"cell_type":"markdown","metadata":{"id":"aJh_lyrsd_cY"},"source":["## 1. Exploratory Naive Bayes\n","\n","We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text\n","for each party and prepare it for use in Naive Bayes."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"GhuVqybqd_cY","executionInfo":{"status":"ok","timestamp":1727843143476,"user_tz":300,"elapsed":252,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["convention_data = []\n","\n","\n","\n","query_results = convention_cur.execute(\n","    '''\n","    SELECT text, party\n","    FROM conventions\n","    WHERE party != \"Other\"\n","    '''\n",")\n","\n","for row in query_results:\n","    speech_text = row[0]\n","    party = row[1]\n","    convention_data.append([speech_text, party])\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Er0CHyvxd_cZ","executionInfo":{"status":"ok","timestamp":1727843145851,"user_tz":300,"elapsed":254,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["# it's a best practice to close up your DB connection when you're done\n","convention_db.close()"]},{"cell_type":"markdown","metadata":{"id":"_zeCEvB_d_cZ"},"source":["Let's look at some random entries and see if they look right."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lPJDYavxd_ca","executionInfo":{"status":"ok","timestamp":1727843422678,"user_tz":300,"elapsed":979,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"f971af2a-c5e8-44b9-99c6-77b4b947582c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['When she was second lady, Jill told me that she would like to continue teaching at community college. And I said, “That’s insane. You cannot possibly do that.” Dr.',\n","  'Democratic'],\n"," ['His entire campaign was for all Americans. That was a turning point for me.',\n","  'Republican'],\n"," ['This week marks the 100th anniversary of the passage of the 19th Amendment, and we celebrate the women who fought for that right, yet so many of the black women who helped secure that victory were still prohibited from voting long after its ratification, but they were undeterred without fanfare or recognition they organized and testified and rallied and marched and fought, not just for their vote but for a seat at the table.',\n","  'Democratic'],\n"," ['We will never, ever sign bad trade deals. America first, again, America first.',\n","  'Republican'],\n"," ['And that our recovery is truly people up, families up, and communities up.',\n","  'Democratic']]"]},"metadata":{},"execution_count":11}],"source":["random.choices(convention_data,k=5)"]},{"cell_type":"markdown","metadata":{"id":"JuftIgIud_ca"},"source":["It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html)."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"nRK0GFfHd_ca","executionInfo":{"status":"ok","timestamp":1727843837466,"user_tz":300,"elapsed":509,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["conv_sent_data = []\n","\n","for speech, party in convention_data:\n","    sentences = sent_tokenize(speech)\n","    for sentence in sentences:\n","        conv_sent_data.append([sentence, party])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"cK-1-yrZd_cb"},"source":["Again, let's look at some random entries."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDrJsuFid_cb","executionInfo":{"status":"ok","timestamp":1727843840597,"user_tz":300,"elapsed":243,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"56b85462-dea7-4b19-a5a4-3a41f82e86cf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['And I gave my speech with much vigor to a completely empty chamber.',\n","  'Democratic'],\n"," ['I am 11 years old.', 'Democratic'],\n"," ['It’s truly heroic.', 'Democratic'],\n"," ['Joe Biden said black people are a monolithic community.', 'Republican'],\n"," ['Not so for President Trump.', 'Republican']]"]},"metadata":{},"execution_count":15}],"source":["random.choices(conv_sent_data,k=5)"]},{"cell_type":"markdown","metadata":{"id":"jxGfXJKPd_cb"},"source":["Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps:\n","\n","1. Tokenize on whitespace\n","1. Remove punctuation\n","1. Remove tokens that fail the `isalpha` test\n","1. Remove stopwords\n","1. Casefold to lowercase\n","1. Join the remaining tokens into a string\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tHpkOQ4d_cb","executionInfo":{"status":"ok","timestamp":1727844346450,"user_tz":300,"elapsed":272,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"4626741e-37c3-4d69-9782-7d313d0d85f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('president reactivated white house council native american promote economic development rural prosperity indian',\n","  'Republican'),\n"," ('president trump first leader savvy crushed status quo establishment political media',\n","  'Republican'),\n"," ('clear', 'Democratic'),\n"," ('', 'Democratic'),\n"," ('instead left could lead world', 'Democratic')]"]},"metadata":{},"execution_count":24}],"source":["stop_words = set(stopwords.words('english'))\n","\n","clean_conv_sent_data = [] # list of tuples (sentence, party), with sentence cleaned\n","\n","# This code was supported with the help of GitHub Copilot\n","for idx, (sentence, party) in enumerate(conv_sent_data):\n","    tokens = sentence.split()\n","\n","    tokens = [word for word in tokens if word.isalpha()]\n","\n","    tokens = [word.casefold() for word in tokens if word.casefold() not in stop_words]\n","\n","    cleaned_sentence = ' '.join(tokens)\n","\n","    clean_conv_sent_data.append((cleaned_sentence, party))\n","\n","random.choices(clean_conv_sent_data, k=5)"]},{"cell_type":"markdown","metadata":{"id":"_C0MQBYQd_cc"},"source":["If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IjqlgNZ3d_cc","executionInfo":{"status":"ok","timestamp":1727844348258,"user_tz":300,"elapsed":225,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"3f9eea48-cd60-4dcc-a4ae-5e3c5a1c9c87"},"outputs":[{"output_type":"stream","name":"stdout","text":["With a word cutoff of 5, we have 1776 as features in the model.\n"]}],"source":["word_cutoff = 5\n","\n","tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n","\n","word_dist = nltk.FreqDist(tokens)\n","\n","feature_words = set()\n","\n","for word, count in word_dist.items() :\n","    if count > word_cutoff :\n","        feature_words.add(word)\n","\n","print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"IQEzTCyCd_cc","executionInfo":{"status":"ok","timestamp":1727844485111,"user_tz":300,"elapsed":224,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["def conv_features(text, fw):\n","    \"\"\"Given some text, this returns a dictionary holding the\n","       feature words.\n","\n","       Args:\n","            * text: a piece of text in a continuous string. Assumes\n","            text has been cleaned and case folded.\n","            * fw: the *feature words* that we're considering. A word\n","            in `text` must be in fw in order to be returned. This\n","            prevents us from considering very rarely occurring words.\n","\n","       Returns:\n","            A dictionary with the words in `text` that appear in `fw`.\n","            Words are only counted once.\n","            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n","            then this would return a dictionary of\n","            {'quick' : True,\n","             'fox' :    True}\n","\n","    \"\"\"\n","    # This code was supported with the help of GitHub Copilot\n","    ret_dict = {}\n","    words = text.split()\n","    for word in words:\n","        if word in fw:\n","            ret_dict[word] = True\n","    return ret_dict\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"7pFKXA7Pd_cd","executionInfo":{"status":"ok","timestamp":1727844487490,"user_tz":300,"elapsed":230,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["assert(len(feature_words)>0)\n","assert(conv_features(\"obama was the president\",feature_words)==\n","       {'obama':True,'president':True})\n","assert(conv_features(\"some people in america are citizens\",feature_words)==\n","                     {'people':True,'america':True,\"citizens\":True})"]},{"cell_type":"markdown","metadata":{"id":"cPP1go69d_cd"},"source":["Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory."]},{"cell_type":"code","execution_count":36,"metadata":{"id":"EsPBeiOsd_cd","executionInfo":{"status":"ok","timestamp":1727844490177,"user_tz":300,"elapsed":232,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"J7hxFAa0d_cd","executionInfo":{"status":"ok","timestamp":1727844490977,"user_tz":300,"elapsed":197,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["random.seed(20220507)\n","random.shuffle(featuresets)\n","\n","test_size = 500"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fB17AOGkd_cd","executionInfo":{"status":"ok","timestamp":1727844491752,"user_tz":300,"elapsed":186,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"a2961856-75c2-4651-fc54-fc5907de2abe"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.494\n"]}],"source":["test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n","classifier = nltk.NaiveBayesClassifier.train(train_set)\n","print(nltk.classify.accuracy(classifier, test_set))"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cx1Rzlj5d_cd","executionInfo":{"status":"ok","timestamp":1727844495689,"user_tz":300,"elapsed":202,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"63a51c7a-0a1d-4a51-a11d-76d1b3f267ab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Most Informative Features\n","             enforcement = True           Republ : Democr =     27.5 : 1.0\n","                   votes = True           Democr : Republ =     21.6 : 1.0\n","                 climate = True           Democr : Republ =     17.3 : 1.0\n","                 destroy = True           Republ : Democr =     17.1 : 1.0\n","                supports = True           Republ : Democr =     16.1 : 1.0\n","                   media = True           Republ : Democr =     15.9 : 1.0\n","                preserve = True           Republ : Democr =     15.1 : 1.0\n","                  signed = True           Republ : Democr =     15.1 : 1.0\n","              appreciate = True           Republ : Democr =     14.0 : 1.0\n","                freedoms = True           Republ : Democr =     14.0 : 1.0\n","                 private = True           Republ : Democr =     11.9 : 1.0\n","                  defund = True           Republ : Democr =     10.9 : 1.0\n","                    drug = True           Republ : Democr =     10.3 : 1.0\n","                 special = True           Republ : Democr =     10.3 : 1.0\n","                   trade = True           Republ : Democr =     10.0 : 1.0\n","                everyday = True           Republ : Democr =      9.9 : 1.0\n","                   local = True           Republ : Democr =      9.9 : 1.0\n","                 allowed = True           Republ : Democr =      9.7 : 1.0\n","                   elect = True           Democr : Republ =      9.6 : 1.0\n","                   moved = True           Republ : Democr =      9.0 : 1.0\n","                   bless = True           Republ : Democr =      9.0 : 1.0\n","                    land = True           Republ : Democr =      8.9 : 1.0\n","                  agenda = True           Republ : Democr =      8.8 : 1.0\n","               countries = True           Republ : Democr =      8.8 : 1.0\n","                   crime = True           Republ : Democr =      8.8 : 1.0\n"]}],"source":["classifier.show_most_informative_features(25)"]},{"cell_type":"markdown","metadata":{"id":"6cbgQNOGd_ce"},"source":["Write a little prose here about what you see in the classifier. Anything odd or interesting?\n","\n","### My Observations\n","\n","Party-Specific Terms:\n","\n","Republican: Words like \"enforcement\", \"destroy\", \"supports\", \"media\", \"preserve\", \"signed\", \"appreciate\", \"freedoms\", \"private\", \"defund\", \"drug\", \"special\", \"trade\", \"everyday\", \"local\", \"allowed\", \"moved\", \"bless\", \"land\", \"agenda\", \"countries\", \"crime\" are highly indicative of Republican speeches. These terms often relate to law enforcement, media critique, national pride, and conservative policies.\n","\n","Democratic: Words like \"votes\", \"climate\", and \"elect\" are highly indicative of Democratic speeches, reflecting a focus on environmental issues, voting rights, and elections.\n","Strength of Association:\n","\n","The ratio indicates how strongly a word is associated with a particular party. For example, \"enforcement\" is 27.5 times more likely to appear in Republican speeches than Democratic ones. This strong association suggests that these words are key identifiers of the party's rhetoric.\n","Surprising Terms:\n","\n","Some words like \"media\" and \"climate\" have strong associations but might be expected to appear frequently in both parties' speeches due to their relevance in contemporary discourse. However, their strong association with specific parties highlights differing focuses or contexts in which these words are used.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"s9SXiawGd_ce"},"source":["## Part 2: Classifying Congressional Tweets\n","\n","In this part we apply the classifer we just built to a set of tweets by people running for congress\n","in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n","give you the query I used to pull out the tweets. Note that this DB has some big tables and\n","is unindexed, so the query takes a minute or two to run on my machine."]},{"cell_type":"code","execution_count":40,"metadata":{"id":"cEu0bPOvd_ce","executionInfo":{"status":"ok","timestamp":1727844685171,"user_tz":300,"elapsed":784,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["cong_db = sqlite3.connect(\"/content/drive/MyDrive/ADS-509-01/Module4/congressional_data.db\")\n","cong_cur = cong_db.cursor()"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"bYOddIbwd_ce","executionInfo":{"status":"ok","timestamp":1727844709314,"user_tz":300,"elapsed":20622,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["results = cong_cur.execute(\n","        '''\n","           SELECT DISTINCT\n","                  cd.candidate,\n","                  cd.party,\n","                  tw.tweet_text\n","           FROM candidate_data cd\n","           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle\n","               AND cd.candidate == tw.candidate\n","               AND cd.district == tw.district\n","           WHERE cd.party in ('Republican','Democratic')\n","               AND tw.tweet_text NOT LIKE '%RT%'\n","        ''')\n","\n","results = list(results) # Just to store it, since the query is time consuming"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"JcXLJ5rYd_ce","executionInfo":{"status":"ok","timestamp":1727844886371,"user_tz":300,"elapsed":2269,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["tweet_data = []\n","\n","for row in results:\n","    candidate, party, tweet_text = row\n","    tweet_data.append([tweet_text, party])\n","# Now fill up tweet_data with sublists like we did on the convention speeches.\n","# Note that this may take a bit of time, since we have a lot of tweets.\n"]},{"cell_type":"markdown","metadata":{"id":"vqgAS7Vqd_ce"},"source":["There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."]},{"cell_type":"code","execution_count":47,"metadata":{"id":"PFrA5fp8d_ce","executionInfo":{"status":"ok","timestamp":1727844908475,"user_tz":300,"elapsed":184,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["random.seed(20201014)\n","\n","tweet_data_sample = random.choices(tweet_data,k=10)"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrSDTuxdd_ce","executionInfo":{"status":"ok","timestamp":1727845501152,"user_tz":300,"elapsed":199,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"8ade0d2a-715b-44dd-e7e7-cb876e020198"},"outputs":[{"output_type":"stream","name":"stdout","text":["Here's our (cleaned) tweet: mass shooting las vegas horrific act victims families thoughts\n","Actual party is Democratic and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: early morning leaving\n","Actual party is Republican and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: moderates enemies sides assist\n","Actual party is Republican and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: rt national security veterans demanding answers release confidential national security\n","Actual party is Democratic and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: \n","Actual party is Republican and our classifier says Democratic.\n","\n","Here's our (cleaned) tweet: glad attend assure everyone could majority americans still stand traditional\n","Actual party is Democratic and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: everyone wraps flag patriotism avoid discussion racism kneeling honoring troops\n","Actual party is Democratic and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: applaud president decision send national guard protect congress support president including fully funding time stop playing politics national security united\n","Actual party is Republican and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: congress considers disaster relief spending must include funding california fire listen remarks house\n","Actual party is Democratic and our classifier says Republican.\n","\n","Here's our (cleaned) tweet: proud oss helped vanquish malevolent enemies free ever\n","Actual party is Democratic and our classifier says Republican.\n","\n"]}],"source":["\n","# This code was supported with the help of GitHub Copilot\n","def preprocess_tweet(tweet):\n","    # Decode tweet if it's in bytes\n","    if isinstance(tweet, bytes):\n","        tweet = tweet.decode('utf-8')\n","\n","    # Tokenize on whitespace\n","    tokens = tweet.split()\n","\n","    # Remove tokens that fail the isalpha test and stopwords\n","    tokens = [word for word in tokens if word.isalpha()]\n","    tokens = [word.casefold() for word in tokens if word.casefold() not in stop_words]\n","\n","    # Join the remaining tokens into a string\n","    cleaned_tweet = ' '.join(tokens)\n","\n","    return cleaned_tweet\n","\n","for tweet, party in tweet_data_sample:\n","    # Preprocess the tweet\n","    cleaned_tweet = preprocess_tweet(tweet)\n","\n","    estimated_party = classifier.classify(features)\n","\n","    print(f\"Here's our (cleaned) tweet: {cleaned_tweet}\")\n","    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n","    print(\"\")"]},{"cell_type":"markdown","metadata":{"id":"dmvRbBdyd_cf"},"source":["Now that we've looked at it some, let's score a bunch and see how we're doing."]},{"cell_type":"code","execution_count":67,"metadata":{"id":"LTv5pjQpd_cf","executionInfo":{"status":"ok","timestamp":1727845640089,"user_tz":300,"elapsed":1496,"user":{"displayName":"Subin An","userId":"05383555497144403727"}}},"outputs":[],"source":["# This code was supported with the help of GitHub Copilot\n","# dictionary of counts by actual party and estimated party.\n","# first key is actual, second is estimated\n","parties = ['Republican','Democratic']\n","results = defaultdict(lambda: defaultdict(int))\n","\n","for p in parties :\n","    for p1 in parties :\n","        results[p][p1] = 0\n","\n","\n","num_to_score = 10000\n","random.shuffle(tweet_data)\n","\n","for idx, tp in enumerate(tweet_data) :\n","    tweet, party = tp\n"," # Preprocess the tweet\n","    cleaned_tweet = preprocess_tweet(tweet)\n","\n","    # Extract features\n","    features = conv_features(cleaned_tweet, feature_words)\n","\n","    # Estimate the party using the classifier\n","    estimated_party = classifier.classify(features)\n","\n","    results[party][estimated_party] += 1\n","\n","    if idx > num_to_score :\n","        break"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zIEuVUMLd_cf","executionInfo":{"status":"ok","timestamp":1727845618060,"user_tz":300,"elapsed":208,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"22361adc-58eb-4d76-abf6-35dcee1460bf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["defaultdict(<function __main__.<lambda>()>,\n","            {'Republican': defaultdict(int,\n","                         {'Republican': 3329, 'Democratic': 781}),\n","             'Democratic': defaultdict(int,\n","                         {'Republican': 4725, 'Democratic': 1167})})"]},"metadata":{},"execution_count":66}],"source":["results"]},{"cell_type":"markdown","metadata":{"id":"k_82BGKnd_cf"},"source":["### Reflections\n","\n","Misclassification Tendency:\n","\n","The classifier tends to incorrectly classify a significant number of Democratic tweets as Republican (4725 misclassifications). This suggests that the classifier might be biased towards predicting tweets as Republican.\n","The number of misclassifications for Republican tweets as Democratic (781) is much lower in comparison.\n","\n","Possible Reasons for Misclassification:\n","\n","1. Feature Overlap: There might be a significant overlap in the vocabulary used by both parties, leading to confusion in classification.\n","\n","2. Feature Selection: The features selected for the classifier might be more indicative of Republican tweets, or there might be an overrepresentation of Republican-related features in the training set.\n","\n","3. Dataset Imbalance: If the training dataset had more Republican tweets, the classifier could be biased towards predicting Republican.\n","Accuracy:\n","\n","The classifier correctly identifies Republican tweets with a higher accuracy compared to Democratic tweets. This indicates that the classifier might be better at recognizing features associated with Republican tweets."]},{"cell_type":"code","source":["!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n","!pip install pypandoc"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VloIzuEColNt","executionInfo":{"status":"ok","timestamp":1727845861797,"user_tz":300,"elapsed":78050,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"205b44ce-bd6f-47bc-b805-b33beb5fe43a"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n","  fonts-urw-base35 libapache-pom-java libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3\n","  libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common\n","  libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0 libsynctex2\n","  libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern pandoc-data poppler-data\n","  preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n","  rubygems-integration t1utils teckit tex-common tex-gyre texlive-base texlive-binaries\n","  texlive-fonts-recommended texlive-latex-base texlive-latex-recommended texlive-pictures\n","  texlive-plain-generic tipa xfonts-encodings xfonts-utils\n","Suggested packages:\n","  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java\n","  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java texlive-luatex\n","  pandoc-citeproc context wkhtmltopdf librsvg2-bin groff ghc nodejs php python libjs-mathjax\n","  libjs-katex citation-style-language-styles poppler-utils ghostscript fonts-japanese-mincho\n","  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n","  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv | postscript-viewer perl-tk xpdf\n","  | pdf-viewer xzdec texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n","  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n","  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex texlive-pictures-doc vprerex\n","  default-jre-headless tipa-doc\n","The following NEW packages will be installed:\n","  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n","  fonts-urw-base35 libapache-pom-java libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3\n","  libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common\n","  libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0 libsynctex2\n","  libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern pandoc pandoc-data\n","  poppler-data preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc\n","  ruby3.0 rubygems-integration t1utils teckit tex-common tex-gyre texlive texlive-base\n","  texlive-binaries texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n","  texlive-latex-recommended texlive-pictures texlive-plain-generic texlive-xetex tipa\n","  xfonts-encodings xfonts-utils\n","0 upgraded, 59 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 202 MB of archives.\n","After this operation, 728 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.9 [752 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.9 [5,033 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n","Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [115 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm-extensions0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [25.1 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n","Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.7 [50.1 kB]\n","Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\n","Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n","Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n","Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n","Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ruby-webrick all 1.7.0-3 [51.8 kB]\n","Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n","Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.7 [5,113 kB]\n","Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n","Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n","Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n","Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n","Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n","Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n","Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n","Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n","Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc-data all 2.9.2.1-3ubuntu2 [81.8 kB]\n","Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc amd64 2.9.2.1-3ubuntu2 [20.3 MB]\n","Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n","Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n","Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]\n","Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n","Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n","Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n","Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n","Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n","Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n","Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive all 2021.20220204-1 [14.3 kB]\n","Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n","Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n","Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n","Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n","Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n","Get:58 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n","Get:59 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]\n","Fetched 202 MB in 6s (36.6 MB/s)\n","Extracting templates from packages: 100%\n","Preconfiguring packages ...\n","Selecting previously unselected package fonts-droid-fallback.\n","(Reading database ... 123614 files and directories currently installed.)\n","Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n","Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n","Selecting previously unselected package fonts-lato.\n","Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n","Unpacking fonts-lato (2.0-2.1) ...\n","Selecting previously unselected package poppler-data.\n","Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n","Unpacking poppler-data (0.4.11-1) ...\n","Selecting previously unselected package tex-common.\n","Preparing to unpack .../03-tex-common_6.17_all.deb ...\n","Unpacking tex-common (6.17) ...\n","Selecting previously unselected package fonts-urw-base35.\n","Preparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...\n","Unpacking fonts-urw-base35 (20200910-1) ...\n","Selecting previously unselected package libgs9-common.\n","Preparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n","Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n","Selecting previously unselected package libidn12:amd64.\n","Preparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...\n","Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n","Selecting previously unselected package libijs-0.35:amd64.\n","Preparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...\n","Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n","Selecting previously unselected package libjbig2dec0:amd64.\n","Preparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...\n","Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n","Selecting previously unselected package libgs9:amd64.\n","Preparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n","Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n","Selecting previously unselected package libkpathsea6:amd64.\n","Preparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n","Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Selecting previously unselected package libwoff1:amd64.\n","Preparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...\n","Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n","Selecting previously unselected package dvisvgm.\n","Preparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...\n","Unpacking dvisvgm (2.13.1-1) ...\n","Selecting previously unselected package fonts-lmodern.\n","Preparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...\n","Unpacking fonts-lmodern (2.004.5-6.1) ...\n","Selecting previously unselected package fonts-noto-mono.\n","Preparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...\n","Unpacking fonts-noto-mono (20201225-1build1) ...\n","Selecting previously unselected package fonts-texgyre.\n","Preparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...\n","Unpacking fonts-texgyre (20180621-3.1) ...\n","Selecting previously unselected package libapache-pom-java.\n","Preparing to unpack .../16-libapache-pom-java_18-1_all.deb ...\n","Unpacking libapache-pom-java (18-1) ...\n","Selecting previously unselected package libcmark-gfm0.29.0.gfm.3:amd64.\n","Preparing to unpack .../17-libcmark-gfm0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n","Unpacking libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n","Selecting previously unselected package libcmark-gfm-extensions0.29.0.gfm.3:amd64.\n","Preparing to unpack .../18-libcmark-gfm-extensions0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n","Unpacking libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n","Selecting previously unselected package libcommons-parent-java.\n","Preparing to unpack .../19-libcommons-parent-java_43-1_all.deb ...\n","Unpacking libcommons-parent-java (43-1) ...\n","Selecting previously unselected package libcommons-logging-java.\n","Preparing to unpack .../20-libcommons-logging-java_1.2-2_all.deb ...\n","Unpacking libcommons-logging-java (1.2-2) ...\n","Selecting previously unselected package libfontenc1:amd64.\n","Preparing to unpack .../21-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libptexenc1:amd64.\n","Preparing to unpack .../22-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n","Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Selecting previously unselected package rubygems-integration.\n","Preparing to unpack .../23-rubygems-integration_1.18_all.deb ...\n","Unpacking rubygems-integration (1.18) ...\n","Selecting previously unselected package ruby3.0.\n","Preparing to unpack .../24-ruby3.0_3.0.2-7ubuntu2.7_amd64.deb ...\n","Unpacking ruby3.0 (3.0.2-7ubuntu2.7) ...\n","Selecting previously unselected package ruby-rubygems.\n","Preparing to unpack .../25-ruby-rubygems_3.3.5-2_all.deb ...\n","Unpacking ruby-rubygems (3.3.5-2) ...\n","Selecting previously unselected package ruby.\n","Preparing to unpack .../26-ruby_1%3a3.0~exp1_amd64.deb ...\n","Unpacking ruby (1:3.0~exp1) ...\n","Selecting previously unselected package rake.\n","Preparing to unpack .../27-rake_13.0.6-2_all.deb ...\n","Unpacking rake (13.0.6-2) ...\n","Selecting previously unselected package ruby-net-telnet.\n","Preparing to unpack .../28-ruby-net-telnet_0.1.1-2_all.deb ...\n","Unpacking ruby-net-telnet (0.1.1-2) ...\n","Selecting previously unselected package ruby-webrick.\n","Preparing to unpack .../29-ruby-webrick_1.7.0-3_all.deb ...\n","Unpacking ruby-webrick (1.7.0-3) ...\n","Selecting previously unselected package ruby-xmlrpc.\n","Preparing to unpack .../30-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n","Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n","Selecting previously unselected package libruby3.0:amd64.\n","Preparing to unpack .../31-libruby3.0_3.0.2-7ubuntu2.7_amd64.deb ...\n","Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.7) ...\n","Selecting previously unselected package libsynctex2:amd64.\n","Preparing to unpack .../32-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n","Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Selecting previously unselected package libteckit0:amd64.\n","Preparing to unpack .../33-libteckit0_2.5.11+ds1-1_amd64.deb ...\n","Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n","Selecting previously unselected package libtexlua53:amd64.\n","Preparing to unpack .../34-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n","Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Selecting previously unselected package libtexluajit2:amd64.\n","Preparing to unpack .../35-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n","Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Selecting previously unselected package libzzip-0-13:amd64.\n","Preparing to unpack .../36-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n","Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../37-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../38-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6build2) ...\n","Selecting previously unselected package lmodern.\n","Preparing to unpack .../39-lmodern_2.004.5-6.1_all.deb ...\n","Unpacking lmodern (2.004.5-6.1) ...\n","Selecting previously unselected package pandoc-data.\n","Preparing to unpack .../40-pandoc-data_2.9.2.1-3ubuntu2_all.deb ...\n","Unpacking pandoc-data (2.9.2.1-3ubuntu2) ...\n","Selecting previously unselected package pandoc.\n","Preparing to unpack .../41-pandoc_2.9.2.1-3ubuntu2_amd64.deb ...\n","Unpacking pandoc (2.9.2.1-3ubuntu2) ...\n","Selecting previously unselected package preview-latex-style.\n","Preparing to unpack .../42-preview-latex-style_12.2-1ubuntu1_all.deb ...\n","Unpacking preview-latex-style (12.2-1ubuntu1) ...\n","Selecting previously unselected package t1utils.\n","Preparing to unpack .../43-t1utils_1.41-4build2_amd64.deb ...\n","Unpacking t1utils (1.41-4build2) ...\n","Selecting previously unselected package teckit.\n","Preparing to unpack .../44-teckit_2.5.11+ds1-1_amd64.deb ...\n","Unpacking teckit (2.5.11+ds1-1) ...\n","Selecting previously unselected package tex-gyre.\n","Preparing to unpack .../45-tex-gyre_20180621-3.1_all.deb ...\n","Unpacking tex-gyre (20180621-3.1) ...\n","Selecting previously unselected package texlive-binaries.\n","Preparing to unpack .../46-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n","Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n","Selecting previously unselected package texlive-base.\n","Preparing to unpack .../47-texlive-base_2021.20220204-1_all.deb ...\n","Unpacking texlive-base (2021.20220204-1) ...\n","Selecting previously unselected package texlive-fonts-recommended.\n","Preparing to unpack .../48-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n","Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n","Selecting previously unselected package texlive-latex-base.\n","Preparing to unpack .../49-texlive-latex-base_2021.20220204-1_all.deb ...\n","Unpacking texlive-latex-base (2021.20220204-1) ...\n","Selecting previously unselected package texlive-latex-recommended.\n","Preparing to unpack .../50-texlive-latex-recommended_2021.20220204-1_all.deb ...\n","Unpacking texlive-latex-recommended (2021.20220204-1) ...\n","Selecting previously unselected package texlive.\n","Preparing to unpack .../51-texlive_2021.20220204-1_all.deb ...\n","Unpacking texlive (2021.20220204-1) ...\n","Selecting previously unselected package libfontbox-java.\n","Preparing to unpack .../52-libfontbox-java_1%3a1.8.16-2_all.deb ...\n","Unpacking libfontbox-java (1:1.8.16-2) ...\n","Selecting previously unselected package libpdfbox-java.\n","Preparing to unpack .../53-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n","Unpacking libpdfbox-java (1:1.8.16-2) ...\n","Selecting previously unselected package texlive-pictures.\n","Preparing to unpack .../54-texlive-pictures_2021.20220204-1_all.deb ...\n","Unpacking texlive-pictures (2021.20220204-1) ...\n","Selecting previously unselected package texlive-latex-extra.\n","Preparing to unpack .../55-texlive-latex-extra_2021.20220204-1_all.deb ...\n","Unpacking texlive-latex-extra (2021.20220204-1) ...\n","Selecting previously unselected package texlive-plain-generic.\n","Preparing to unpack .../56-texlive-plain-generic_2021.20220204-1_all.deb ...\n","Unpacking texlive-plain-generic (2021.20220204-1) ...\n","Selecting previously unselected package tipa.\n","Preparing to unpack .../57-tipa_2%3a1.3-21_all.deb ...\n","Unpacking tipa (2:1.3-21) ...\n","Selecting previously unselected package texlive-xetex.\n","Preparing to unpack .../58-texlive-xetex_2021.20220204-1_all.deb ...\n","Unpacking texlive-xetex (2021.20220204-1) ...\n","Setting up fonts-lato (2.0-2.1) ...\n","Setting up fonts-noto-mono (20201225-1build1) ...\n","Setting up libwoff1:amd64 (1.0.2-1build4) ...\n","Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Setting up libijs-0.35:amd64 (0.35-15build2) ...\n","Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Setting up libfontbox-java (1:1.8.16-2) ...\n","Setting up rubygems-integration (1.18) ...\n","Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n","Setting up fonts-urw-base35 (20200910-1) ...\n","Setting up poppler-data (0.4.11-1) ...\n","Setting up tex-common (6.17) ...\n","update-language: texlive-base not installed and configured, doing nothing!\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n","Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n","Setting up libapache-pom-java (18-1) ...\n","Setting up ruby-net-telnet (0.1.1-2) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Setting up t1utils (1.41-4build2) ...\n","Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n","Setting up fonts-texgyre (20180621-3.1) ...\n","Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Setting up ruby-webrick (1.7.0-3) ...\n","Setting up libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n","Setting up fonts-lmodern (2.004.5-6.1) ...\n","Setting up libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n","Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n","Setting up pandoc-data (2.9.2.1-3ubuntu2) ...\n","Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n","Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n","Setting up teckit (2.5.11+ds1-1) ...\n","Setting up libpdfbox-java (1:1.8.16-2) ...\n","Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n","Setting up preview-latex-style (12.2-1ubuntu1) ...\n","Setting up libcommons-parent-java (43-1) ...\n","Setting up dvisvgm (2.13.1-1) ...\n","Setting up libcommons-logging-java (1.2-2) ...\n","Setting up xfonts-utils (1:7.7+6build2) ...\n","Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n","Setting up pandoc (2.9.2.1-3ubuntu2) ...\n","Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n","update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n","update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n","Setting up lmodern (2.004.5-6.1) ...\n","Setting up texlive-base (2021.20220204-1) ...\n","/usr/bin/ucfr\n","/usr/bin/ucfr\n","/usr/bin/ucfr\n","/usr/bin/ucfr\n","mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n","mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n","mktexlsr: Updating /var/lib/texmf/ls-R... \n","mktexlsr: Done.\n","tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n","tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n","tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n","tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n","Setting up tex-gyre (20180621-3.1) ...\n","Setting up texlive-plain-generic (2021.20220204-1) ...\n","Setting up texlive-latex-base (2021.20220204-1) ...\n","Setting up texlive-latex-recommended (2021.20220204-1) ...\n","Setting up texlive-pictures (2021.20220204-1) ...\n","Setting up texlive-fonts-recommended (2021.20220204-1) ...\n","Setting up tipa (2:1.3-21) ...\n","Setting up texlive (2021.20220204-1) ...\n","Setting up texlive-latex-extra (2021.20220204-1) ...\n","Setting up texlive-xetex (2021.20220204-1) ...\n","Setting up rake (13.0.6-2) ...\n","Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.7) ...\n","Setting up ruby3.0 (3.0.2-7ubuntu2.7) ...\n","Setting up ruby (1:3.0~exp1) ...\n","Setting up ruby-rubygems (3.3.5-2) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","Processing triggers for tex-common (6.17) ...\n","Running updmap-sys. This may take some time... done.\n","Running mktexlsr /var/lib/texmf ... done.\n","Building format(s) --all.\n","\tThis may take some time... done.\n","Collecting pypandoc\n","  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\n","Downloading pypandoc-1.13-py3-none-any.whl (21 kB)\n","Installing collected packages: pypandoc\n","Successfully installed pypandoc-1.13\n"]}]},{"cell_type":"code","source":["!jupyter nbconvert --to PDF \"/content/drive/MyDrive/ADS-509-01/Module4/Political Naive Bayes.ipynb\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSzUV0MnouvG","executionInfo":{"status":"ok","timestamp":1727846189977,"user_tz":300,"elapsed":12160,"user":{"displayName":"Subin An","userId":"05383555497144403727"}},"outputId":"423c2edc-e109-4865-d72a-40f4d52dee78"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook /content/drive/MyDrive/ADS-509-01/Module4/Political Naive Bayes.ipynb to PDF\n","[NbConvertApp] Writing 89458 bytes to notebook.tex\n","[NbConvertApp] Building PDF\n","[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n","[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n","[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n","[NbConvertApp] PDF successfully created\n","[NbConvertApp] Writing 91847 bytes to /content/drive/MyDrive/ADS-509-01/Module4/Political Naive Bayes.pdf\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}